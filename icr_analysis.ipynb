{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Character Recognition\n",
    "## 1. Descriere\n",
    "\n",
    "ICR (Intelligent Character Recognition) presupune un model de recunoaștere și extragere a textului cursiv din poze. Acest model reprezintă o variantă mai sofisticată a OCR (Optical Character Reader) prin faptul că se poate extrage text din orice tip de scris sau font cursiv. În general, pentru implementarea modelului se folosesc rețele neuronale pentru învățarea tipurilor de scris, ce pot avea grade variate de acuratețe.\n",
    "\n",
    "Pentru setul de date, s-a ales setul Handwriting Recognition (https://www.kaggle.com/datasets/landlord/handwriting-recognition), ce conține 400 de mii de nume scrise de mână, dintre care:\n",
    "- 206799 prenume\n",
    "- 207024 nume\n",
    "\n",
    "Aceste date sunt mai apoi împărțite în:\n",
    "- set de antrenament (331059 nume)\n",
    "- set de testare (41382 nume)\n",
    "- set de validare (41382 nume)\n",
    "\n",
    "### 1.1 Dependințe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dependency in c:\\users\\andrei usurelu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: dependency in c:\\users\\andrei usurelu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: dependency in c:\\users\\andrei usurelu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: dependency in c:\\users\\andrei usurelu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: dependency in c:\\users\\andrei usurelu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: dependency in c:\\users\\andrei usurelu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: dependency in c:\\users\\andrei usurelu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.3)\n"
     ]
    }
   ],
   "source": [
    "dependencies = ['opendatasets', 'pandas', 'matplotlib', 'numpy', 'seaborn', 'sklearn', 'pyvips']\n",
    "for dependency in dependencies:\n",
    "    !python -m pip install dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "from os.path import isdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Încărcarea datelor de antrenament, testare și validare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isdir(\"handwriting-recognition\"):\n",
    "    od.download(\"https://www.kaggle.com/datasets/landlord/handwriting-recognition\")\n",
    "\n",
    "train_data = pd.read_csv(\"handwriting-recognition/written_name_train_v2.csv\")\n",
    "#train_imgs, train_labels = np.array([np.asarray(Image.open('handwriting-recognition/train_v2/train/'+filename)) for filename in np.array(train_data['FILENAME'])], dtype=\"object\"), np.array(train_data['IDENTITY'])\n",
    "\n",
    "test_data = pd.read_csv(\"handwriting-recognition/written_name_test_v2.csv\")\n",
    "#test_imgs, test_labels = np.array([np.asarray(Image.open('handwriting-recognition/test_v2/test/'+filename)) for filename in np.array(test_data['FILENAME'])], dtype=\"object\"), np.array(test_data['IDENTITY'])\n",
    "\n",
    "validation_data = pd.read_csv(\"handwriting-recognition/written_name_validation_v2.csv\")\n",
    "#validation_imgs, validation_labels = np.array([np.asarray(Image.open('handwriting-recognition/validation_v2/validation/'+filename)) for filename in np.array(validation_data['FILENAME'])], dtype=\"object\"), np.array(validation_data['IDENTITY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Curățarea datelor\n",
    "\n",
    "Datele de intrare dintr-un set pot să nu fie corect etichetate, etichetele să fie goale sau să fie etichetate cu \"UNREADABLE\". Dacă eticheta este scrisă cu litere mici, atunci se va schimba în litere mari. Altfel, pentru date corupte sau goale se va aplica ștergerea lor. Datorită tipului de date, nu se va verifica unicitatea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN label values on train dataset:  565\n",
      "Number of NaN label values on test dataset:  70\n",
      "Number of NaN label values on validation dataset:  78\n"
     ]
    }
   ],
   "source": [
    "# ștergem intrările fără etichetă\n",
    "noEmptyLabels = train_data['IDENTITY'].isnull().sum()\n",
    "if noEmptyLabels > 0:\n",
    "    print('Number of NaN label values on train dataset: ', noEmptyLabels)\n",
    "    train_data.dropna(axis=0, inplace=True)\n",
    "\n",
    "noEmptyLabels = test_data['IDENTITY'].isnull().sum()\n",
    "if noEmptyLabels > 0:\n",
    "    print('Number of NaN label values on test dataset: ', noEmptyLabels)\n",
    "    test_data.dropna(axis=0, inplace=True)\n",
    "\n",
    "noEmptyLabels = validation_data['IDENTITY'].isnull().sum()\n",
    "if noEmptyLabels > 0:\n",
    "    print('Number of NaN label values on validation dataset: ', noEmptyLabels)\n",
    "    validation_data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Exemple din setul de date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m idxs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(train_imgs), \u001b[39m5\u001b[39m)\n\u001b[0;32m      2\u001b[0m fig,axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(nrows\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, ncols\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m50\u001b[39m, \u001b[39m50\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(train_data[\u001b[39m'\u001b[39m\u001b[39mFILENAME\u001b[39m\u001b[39m'\u001b[39m][idxs])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "idxs = np.random.randint(0, len(train_imgs), 5)\n",
    "fig,axes = plt.subplots(nrows=5, ncols=1, figsize=(50, 50))\n",
    "print(train_data['FILENAME'][idxs])\n",
    "for i, idx in enumerate(idxs):\n",
    "    axes[i].imshow(train_imgs[idx])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(train_labels[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Standardizarea datelor\n",
    "\n",
    "Datele de intrare (imaginile) vor fi rescalate pentru a avea media zero și deviația standard 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construirea unei rețele de tip feed-forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construirea unei rețele convoluționale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construirea unei rețele recurente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
